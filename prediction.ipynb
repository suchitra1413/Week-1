{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1a58aa9"
      },
      "source": [
        "# Task\n",
        "Load the dataset \"My Drive/customer_data.csv\" from Google Drive into a dataframe and display the first 5 rows and the columns and their types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c79acb2b"
      },
      "source": [
        "## Mount google drive\n",
        "\n",
        "### Subtask:\n",
        "Mount your Google Drive to access files stored there.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9fc6678"
      },
      "source": [
        "**Reasoning**:\n",
        "Mount Google Drive to access the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ac5d749",
        "outputId": "a0ab21c8-caa6-49f7-bc86-18a29883ef05"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bb30b80"
      },
      "source": [
        "The error `NameError: name 'content' is not defined` in cell `YpR3o5d8j64e` occurs because `/content/drive/MyDrive/` is a file path, not valid Python code that can be directly executed.\n",
        "\n",
        "If you intended to list the contents of that directory, you can use a shell command by prefixing the line with `!`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2bbb350",
        "outputId": "248e56a0-25af-4ac8-e86e-54245e1b0078"
      },
      "source": [
        "!ls /content/drive/MyDrive/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 23STUCHH011171_Pranav-Jaina_Viswam-AI_Report.docx\n",
            " 23STUCHH011179_Bhanuri_Suchitra_Viswam-AI_IPReport.docx\n",
            "'23STUCHH011179_PBhanuri_Suchitra_Viswam-AI_Report[1] (1).docx'\n",
            "'23STUCHH011179_PBhanuri_Suchitra_Viswam-AI_Report[1].docx'\n",
            " 23STUCHH011179_PBhanuri_Suchitra_Viswam-AI_Report.docx\n",
            " 2608251516485527.gdoc\n",
            "'3-02-25 (1).rtf.gdoc'\n",
            " 3-02-25.rtf.gdoc\n",
            " Assignment.gdoc\n",
            "'Colab Notebooks'\n",
            "'Copy of 23STUCHH011179_PBhanuri_Suchitra_Viswam-AI_Report.docx'\n",
            " DS305_Labexam_Sets15oct2025.gdoc\n",
            "'DWV ASSIGNMENT 1179.docx'\n",
            "'DWV ASSIGNMENT.gdoc'\n",
            " IMG_20210618_130307.jpg\n",
            "'koushik resume.pdf'\n",
            "'Report IP1 (1).gdoc'\n",
            "'Report IP1.gdoc'\n",
            "'Report IP1.pdf'\n",
            " ReportSuchitra.docx\n",
            " Snapchat-1842695788.jpg\n",
            " Test.csv\n",
            " Train.csv\n",
            " VISWAM_AI_Seminar_Presentation_11179.pptx\n",
            " wordpress.gdoc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Train.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OSqnP7yk-8O",
        "outputId": "d730a8c1-7087-4dbf-a515-61e730e0d5e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Import libraries ---\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# --- Step 2: Load datasets ---\n",
        "train_path = '/content/drive/MyDrive/Train.csv'  # Update if your file is in another folder\n",
        "test_path = '/content/drive/MyDrive/Test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "print(\"\\nPreview of Train data:\")\n",
        "print(train_df.head())\n",
        "\n",
        "# --- Step 3: Handle missing values ---\n",
        "# Fill numeric missing values with mean\n",
        "train_df = train_df.fillna(train_df.mean(numeric_only=True))\n",
        "test_df = test_df.fillna(test_df.mean(numeric_only=True))\n",
        "\n",
        "# --- Step 4: Encode categorical columns ---\n",
        "label_enc = LabelEncoder()\n",
        "\n",
        "# Find categorical columns (object/string type)\n",
        "cat_cols = train_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in cat_cols:\n",
        "    # Combine train + test for consistent encoding\n",
        "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
        "    label_enc.fit(combined.astype(str))\n",
        "    train_df[col] = label_enc.transform(train_df[col].astype(str))\n",
        "    test_df[col] = label_enc.transform(test_df[col].astype(str))\n",
        "\n",
        "# --- Step 5: Separate features and target ---\n",
        "target = 'Power'\n",
        "\n",
        "X_train = train_df.drop(columns=[target])\n",
        "y_train = train_df[target]\n",
        "\n",
        "# Note: Test data usually has no 'Power' column\n",
        "if 'Power' in test_df.columns:\n",
        "    X_test = test_df.drop(columns=[target])\n",
        "    y_test = test_df[target]\n",
        "else:\n",
        "    X_test = test_df.copy()\n",
        "    y_test = None\n",
        "\n",
        "# --- Step 6: Scale numeric data ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nâœ… Data preprocessing completed successfully!\")\n",
        "print(\"Training features shape:\", X_train_scaled.shape)\n",
        "print(\"Test features shape:\", X_test_scaled.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m092DlpwotWe",
        "outputId": "b4f50ced-fe92-4c4d-85d7-73d264900c89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (140160, 12)\n",
            "Test shape: (35040, 11)\n",
            "\n",
            "Preview of Train data:\n",
            "   Unnamed: 0              Time  Location  Temp_2m  RelHum_2m      DP_2m  \\\n",
            "0           0  02-01-2013 00:00         1  28.2796  84.664205  24.072595   \n",
            "1           1  02-01-2013 01:00         1  28.1796  85.664205  24.272595   \n",
            "2           2  02-01-2013 02:00         1  26.5796  90.664205  24.072595   \n",
            "3           3  02-01-2013 03:00         1  27.1796  87.664205  23.872595   \n",
            "4           4  02-01-2013 04:00         1  27.0796  87.664205  23.672595   \n",
            "\n",
            "     WS_10m   WS_100m      WD_10m     WD_100m    WG_10m     Power  \n",
            "0  1.605389  1.267799  145.051683  161.057315  1.336515  0.163496  \n",
            "1  2.225389  3.997799  150.051683  157.057315  4.336515  0.142396  \n",
            "2  1.465389  2.787799  147.051683  149.057315  3.136515  0.121396  \n",
            "3  1.465389  2.697799   57.051683  104.057315  1.536515  0.100296  \n",
            "4  2.635389  4.437799   57.051683   83.057315  3.936515  0.079296  \n",
            "\n",
            "âœ… Data preprocessing completed successfully!\n",
            "Training features shape: (140160, 11)\n",
            "Test features shape: (35040, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "H6qv0BedFAgz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"âœ… Model training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTNpA41kFQ7Q",
        "outputId": "0d94c20e-9b91-4d5a-9146-7336d013dfe0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(X_test_scaled)\n",
        "print(\"Predictions on Test data:\")\n",
        "print(y_pred_test[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7Gq13KHFWon",
        "outputId": "7b02ad03-1f37-46d8-cd09-22d83bdeacbc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions on Test data:\n",
            "[-0.04979993  0.00850635  0.05840822  0.10189542  0.12253005  0.09845246\n",
            "  0.07454005  0.09562673  0.20506185  0.27197684]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if y_test is not None:\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(\"\\nðŸ“Š Evaluation Results:\")\n",
        "    print(\"MAE :\", mae)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"RÂ² Score:\", r2)\n"
      ],
      "metadata": {
        "id": "aWab6I4dGbO-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Import libraries ---\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Train.csv'  # Update if your file is in another folder\n",
        "test_path = '/content/drive/MyDrive/Test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "\n",
        "print(\"âœ… Data Loaded Successfully!\")\n",
        "print(\"Train Shape:\", train_df.shape)\n",
        "print(\"Test Shape:\", test_df.shape)\n",
        "\n",
        "# --- Step 3: Handle missing values ---\n",
        "train_df = train_df.fillna(train_df.mean(numeric_only=True))\n",
        "test_df = test_df.fillna(test_df.mean(numeric_only=True))\n",
        "\n",
        "# --- Step 4: Encode categorical columns ---\n",
        "label_enc = LabelEncoder()\n",
        "for col in train_df.select_dtypes(include=['object']).columns:\n",
        "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
        "    label_enc.fit(combined.astype(str))\n",
        "    train_df[col] = label_enc.transform(train_df[col].astype(str))\n",
        "    test_df[col] = label_enc.transform(test_df[col].astype(str))\n",
        "\n",
        "# --- Step 5: Separate features and target ---\n",
        "target = \"Power\"\n",
        "X_train = train_df.drop(columns=[target])\n",
        "y_train = train_df[target]\n",
        "X_test = test_df.copy()  # test has no target column\n",
        "\n",
        "# --- Step 6: Scale features ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# --- Step 7: Train model ---\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(\"âœ… Model Trained Successfully!\")\n",
        "\n",
        "# --- Step 8: Predict on test data ---\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(\"\\nâœ… Predictions generated successfully!\")\n",
        "print(\"First 10 predicted Power values:\")\n",
        "print(y_pred[:10])\n",
        "\n",
        "# --- Step 9: Prepare output file ---\n",
        "# If test data has an ID column, include it\n",
        "id_columns = [col for col in test_df.columns if col.lower() in ['id', 'index']]\n",
        "if id_columns:\n",
        "    output = pd.DataFrame({\n",
        "        id_columns[0]: test_df[id_columns[0]],\n",
        "        'Predicted_Power': y_pred\n",
        "    })\n",
        "else:\n",
        "    # If no ID column, create one\n",
        "    output = pd.DataFrame({\n",
        "        'ID': range(1, len(y_pred) + 1),\n",
        "        'Predicted_Power': y_pred\n",
        "    })\n",
        "\n",
        "# --- Step 10: Save predictions ---\n",
        "output.to_csv('Predicted_Power.csv', index=False)\n",
        "print(\"\\nðŸ’¾ Predictions saved to 'Predicted_Power.csv'\")\n",
        "print(\"\\nPreview of saved file:\")\n",
        "print(output.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbMNpS7MHzaV",
        "outputId": "4b775948-89e7-4c7e-d8cd-0a8dfd96de05"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Data Loaded Successfully!\n",
            "Train Shape: (140160, 12)\n",
            "Test Shape: (35040, 11)\n",
            "âœ… Model Trained Successfully!\n",
            "\n",
            "âœ… Predictions generated successfully!\n",
            "First 10 predicted Power values:\n",
            "[-0.04979993  0.00850635  0.05840822  0.10189542  0.12253005  0.09845246\n",
            "  0.07454005  0.09562673  0.20506185  0.27197684]\n",
            "\n",
            "ðŸ’¾ Predictions saved to 'Predicted_Power.csv'\n",
            "\n",
            "Preview of saved file:\n",
            "   ID  Predicted_Power\n",
            "0   1        -0.049800\n",
            "1   2         0.008506\n",
            "2   3         0.058408\n",
            "3   4         0.101895\n",
            "4   5         0.122530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf.fit(X_train_split, y_train_split)\n",
        "y_val_pred = rf.predict(X_val_split)\n",
        "\n",
        "mae = mean_absolute_error(y_val_split, y_val_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val_split, y_val_pred))\n",
        "r2 = r2_score(y_val_split, y_val_pred)\n",
        "\n",
        "print(\"\\nModel Accuracy on Validation Data:\")\n",
        "print(f\"MAE  : {mae:.4f}\")\n",
        "print(f\"RMSE : {rmse:.4f}\")\n",
        "print(f\"RÂ²   : {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX2r-RZpIpWu",
        "outputId": "8072fc56-5749-443d-ee80-0c0a0ae33191"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy on Validation Data:\n",
            "MAE  : 0.0737\n",
            "RMSE : 0.1054\n",
            "RÂ²   : 0.8272\n"
          ]
        }
      ]
    }
  ]
}